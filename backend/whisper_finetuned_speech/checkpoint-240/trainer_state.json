{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 12.0,
  "eval_steps": 500,
  "global_step": 240,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 19.731046676635742,
      "learning_rate": 9.960000000000001e-05,
      "loss": 6.1131,
      "step": 5
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 9.917762756347656,
      "learning_rate": 9.910000000000001e-05,
      "loss": 5.4334,
      "step": 10
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 6.141446590423584,
      "learning_rate": 9.86e-05,
      "loss": 5.2574,
      "step": 15
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.291156768798828,
      "learning_rate": 9.81e-05,
      "loss": 4.5172,
      "step": 20
    },
    {
      "epoch": 1.2531645569620253,
      "grad_norm": 6.600955963134766,
      "learning_rate": 9.76e-05,
      "loss": 4.1484,
      "step": 25
    },
    {
      "epoch": 1.5063291139240507,
      "grad_norm": 6.438531398773193,
      "learning_rate": 9.71e-05,
      "loss": 3.8775,
      "step": 30
    },
    {
      "epoch": 1.759493670886076,
      "grad_norm": 7.008595943450928,
      "learning_rate": 9.66e-05,
      "loss": 3.6751,
      "step": 35
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.986820220947266,
      "learning_rate": 9.61e-05,
      "loss": 3.5045,
      "step": 40
    },
    {
      "epoch": 2.2531645569620253,
      "grad_norm": 7.412761688232422,
      "learning_rate": 9.56e-05,
      "loss": 3.1169,
      "step": 45
    },
    {
      "epoch": 2.5063291139240507,
      "grad_norm": 6.435118675231934,
      "learning_rate": 9.51e-05,
      "loss": 2.523,
      "step": 50
    },
    {
      "epoch": 2.759493670886076,
      "grad_norm": 6.349609851837158,
      "learning_rate": 9.46e-05,
      "loss": 2.5105,
      "step": 55
    },
    {
      "epoch": 3.0,
      "grad_norm": 7.562082290649414,
      "learning_rate": 9.41e-05,
      "loss": 2.3013,
      "step": 60
    },
    {
      "epoch": 3.2531645569620253,
      "grad_norm": 5.024296283721924,
      "learning_rate": 9.360000000000001e-05,
      "loss": 2.2049,
      "step": 65
    },
    {
      "epoch": 3.5063291139240507,
      "grad_norm": 6.271437644958496,
      "learning_rate": 9.310000000000001e-05,
      "loss": 1.9153,
      "step": 70
    },
    {
      "epoch": 3.759493670886076,
      "grad_norm": 5.424072265625,
      "learning_rate": 9.260000000000001e-05,
      "loss": 1.7419,
      "step": 75
    },
    {
      "epoch": 4.0,
      "grad_norm": 8.219731330871582,
      "learning_rate": 9.21e-05,
      "loss": 1.8245,
      "step": 80
    },
    {
      "epoch": 4.253164556962025,
      "grad_norm": 5.420848369598389,
      "learning_rate": 9.16e-05,
      "loss": 1.7386,
      "step": 85
    },
    {
      "epoch": 4.506329113924051,
      "grad_norm": 6.561211585998535,
      "learning_rate": 9.11e-05,
      "loss": 1.6915,
      "step": 90
    },
    {
      "epoch": 4.759493670886076,
      "grad_norm": 5.888486862182617,
      "learning_rate": 9.06e-05,
      "loss": 1.3288,
      "step": 95
    },
    {
      "epoch": 5.0,
      "grad_norm": 5.378714084625244,
      "learning_rate": 9.010000000000001e-05,
      "loss": 1.3568,
      "step": 100
    },
    {
      "epoch": 5.253164556962025,
      "grad_norm": 3.669459819793701,
      "learning_rate": 8.960000000000001e-05,
      "loss": 1.3827,
      "step": 105
    },
    {
      "epoch": 5.506329113924051,
      "grad_norm": 5.72630500793457,
      "learning_rate": 8.910000000000001e-05,
      "loss": 1.3347,
      "step": 110
    },
    {
      "epoch": 5.759493670886076,
      "grad_norm": 4.334919452667236,
      "learning_rate": 8.86e-05,
      "loss": 1.291,
      "step": 115
    },
    {
      "epoch": 6.0,
      "grad_norm": 5.555732250213623,
      "learning_rate": 8.81e-05,
      "loss": 1.2163,
      "step": 120
    },
    {
      "epoch": 6.253164556962025,
      "grad_norm": 4.783658981323242,
      "learning_rate": 8.76e-05,
      "loss": 0.9949,
      "step": 125
    },
    {
      "epoch": 6.506329113924051,
      "grad_norm": 3.9472296237945557,
      "learning_rate": 8.71e-05,
      "loss": 0.9989,
      "step": 130
    },
    {
      "epoch": 6.759493670886076,
      "grad_norm": 6.2748613357543945,
      "learning_rate": 8.66e-05,
      "loss": 1.1515,
      "step": 135
    },
    {
      "epoch": 7.0,
      "grad_norm": 9.904277801513672,
      "learning_rate": 8.61e-05,
      "loss": 1.1233,
      "step": 140
    },
    {
      "epoch": 7.253164556962025,
      "grad_norm": 5.162744998931885,
      "learning_rate": 8.560000000000001e-05,
      "loss": 0.7695,
      "step": 145
    },
    {
      "epoch": 7.506329113924051,
      "grad_norm": 4.926236152648926,
      "learning_rate": 8.510000000000001e-05,
      "loss": 0.9844,
      "step": 150
    },
    {
      "epoch": 7.759493670886076,
      "grad_norm": 4.521048069000244,
      "learning_rate": 8.46e-05,
      "loss": 0.8624,
      "step": 155
    },
    {
      "epoch": 8.0,
      "grad_norm": 5.950946807861328,
      "learning_rate": 8.41e-05,
      "loss": 0.9666,
      "step": 160
    },
    {
      "epoch": 8.253164556962025,
      "grad_norm": 3.619189500808716,
      "learning_rate": 8.36e-05,
      "loss": 0.9169,
      "step": 165
    },
    {
      "epoch": 8.50632911392405,
      "grad_norm": 3.9922609329223633,
      "learning_rate": 8.31e-05,
      "loss": 0.7444,
      "step": 170
    },
    {
      "epoch": 8.759493670886076,
      "grad_norm": 3.806288242340088,
      "learning_rate": 8.26e-05,
      "loss": 0.7683,
      "step": 175
    },
    {
      "epoch": 9.0,
      "grad_norm": 4.615965843200684,
      "learning_rate": 8.21e-05,
      "loss": 0.855,
      "step": 180
    },
    {
      "epoch": 9.253164556962025,
      "grad_norm": 4.403070449829102,
      "learning_rate": 8.16e-05,
      "loss": 0.7444,
      "step": 185
    },
    {
      "epoch": 9.50632911392405,
      "grad_norm": 4.264815330505371,
      "learning_rate": 8.11e-05,
      "loss": 0.7635,
      "step": 190
    },
    {
      "epoch": 9.759493670886076,
      "grad_norm": 4.228424549102783,
      "learning_rate": 8.060000000000001e-05,
      "loss": 0.7226,
      "step": 195
    },
    {
      "epoch": 10.0,
      "grad_norm": 4.7410888671875,
      "learning_rate": 8.010000000000001e-05,
      "loss": 0.8572,
      "step": 200
    },
    {
      "epoch": 10.253164556962025,
      "grad_norm": 3.987682580947876,
      "learning_rate": 7.960000000000001e-05,
      "loss": 0.6141,
      "step": 205
    },
    {
      "epoch": 10.50632911392405,
      "grad_norm": 4.9741902351379395,
      "learning_rate": 7.910000000000001e-05,
      "loss": 0.6657,
      "step": 210
    },
    {
      "epoch": 10.759493670886076,
      "grad_norm": 3.880720615386963,
      "learning_rate": 7.860000000000001e-05,
      "loss": 0.716,
      "step": 215
    },
    {
      "epoch": 11.0,
      "grad_norm": 5.039191722869873,
      "learning_rate": 7.81e-05,
      "loss": 0.9415,
      "step": 220
    },
    {
      "epoch": 11.253164556962025,
      "grad_norm": 3.79884934425354,
      "learning_rate": 7.76e-05,
      "loss": 0.6818,
      "step": 225
    },
    {
      "epoch": 11.50632911392405,
      "grad_norm": 3.893779754638672,
      "learning_rate": 7.71e-05,
      "loss": 0.6508,
      "step": 230
    },
    {
      "epoch": 11.759493670886076,
      "grad_norm": 3.9087119102478027,
      "learning_rate": 7.66e-05,
      "loss": 0.7669,
      "step": 235
    },
    {
      "epoch": 12.0,
      "grad_norm": 5.033111572265625,
      "learning_rate": 7.61e-05,
      "loss": 0.6799,
      "step": 240
    }
  ],
  "logging_steps": 5,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.188986662912e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
